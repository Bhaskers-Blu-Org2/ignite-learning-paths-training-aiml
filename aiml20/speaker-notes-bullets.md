# <a name="aiml20-speaker-notes"></a>AIML20：演讲者备注

如果你希望根据要点而不是脚本文本进行讲述，下面是 PPT 演示文稿的每张幻灯片中的要点：[presentations.md](https://github.com/microsoft/ignite-learning-paths-training-aiml/blob/master/aiml20/presentations.md)

相关的演示脚本可在以下位置找到： https://github.com/microsoft/ignite-learning-paths-training-aiml/tree/master/aiml20 。 从 `DEMO%20Setup.md` 开始。

## <a name="slide-notes"></a>幻灯片备注

幻灯片仅按标题标识。

### <a name="slide-microsoft-ignite-the-tour"></a>幻灯片：Microsft Ignite 巡演

演示前的开题幻灯片

### <a name="slide-using-pre-built-ai-to-solve-business-problems"></a>幻灯片：使用预构建的 AI 来解决业务问题

自我介绍。

如何将 AI 功能添加到应用程序（即使没有计算资源或 AI 专业知识）。

使用云中预构建的 AI 服务。

### <a name="slide-resources"></a>幻灯片：资源

我们将提供大量链接、资源和演示。

所有信息，包括完整源代码和应用一键式部署，在此处都以链接的形式提供。

最后会再次显示此幻灯片。

### <a name="slide-adding-humanlike-capabilities-to-apps"></a>幻灯片：向应用添加与人相似的功能

我们将使用预构建的 AI 服务向应用程序添加类似于人的功能，但这是什么意思呢？ 下面是一些例子。

### <a name="slide-enhance-apps-with-humanlike-capabilities"></a>幻灯片：借助类似于人的功能增强应用

[点击声] 为应用赋予语音能力（例如聊天）。
 
[点击声] 为应用赋予观察能力（识别图像）。

[点击声] 为应用赋予类似于人的直觉（适配接口）。

[点击声] 为应用赋予领悟能力（以任何语言进行沟通）

[点击声] 自动化扫描数据流中异常的人工过程（和缩放）

这只是一些示例。

### <a name="slide-overview-of-azure-cognitive-services"></a>幻灯片：Azure 认知服务概述

实现类似于人的 AI 是否需要引入大量的数据并具备丰富的技术专业知识？

否。 可利用 Microsoft Research 的专业技术。 通过简单的 REST API 调用即可添加功能。 

这就是 Azure 认知服务。

### <a name="slide-azure-cognitive-services"></a>幻灯片：Azure 认知服务

Azure 认知服务包含二十多个 API。

这些服务属于下列人类能力类别：

视觉：理解照片、绘画、文本、手写资料和视频中的内容

语音：用于理解和识别语音并生成类人自然口语的工具。

语言:理解书面文档和文本的内容，并翻译成不同的人类语言。

决策：Azure 认知服务的全新类别，关于像人一样对数据、内容和应用程序用户界面作出选择。

搜索：回答用自然语言表述的关于大型非结构化存储库的内容的问题。 

### <a name="slide-azure-cognitive-services-with-service-names"></a>幻灯片：Azure 认知服务（包括服务名称）

已包括“搜索”。 

我们将使用其他一些可用服务来增强某个零售网站：[点击声]

计算机视觉：我们用它来分析产品照片的内容。

自定义视觉：我们用它来识别零售商们销售的具体产品。

个性化体验创建服务：将自动适应网站布局 

有关设置和使用认知服务的原则对所有 API 来说都相同，所以你今天在这里学到的知识也适用于你想要使用的任何 AI 服务。

### <a name="slide-computer-vision"></a>幻灯片：计算机视觉

首先，我们看一下计算机视觉的预构建 AI。

### <a name="slide-shop-by-photo"></a>幻灯片：按图购物

这是 Tailwind Traders 的网站，它是一家硬件零售商（虚构的公司）。 

### <a name="slide-demo-shop-by-photo"></a>幻灯片：演示：按图购物

演示：“定义问题：按图购物功能失效”

### <a name="video-shop-by-photo"></a>视频：按图购物

让我们转到 Tailwind Traders 实时网站。 [点击声]

AI 支持的其中一项功能称为“按图购物”。 这项功能的构想是，客户可以上传他们想要购买的产品的照片，让应用显示该产品是否有库存。 接下来，让我试一试。 我们将上传这张我们感兴趣的电钻的图片，Tailwind Traders 应用会分析该图片，识别出它是一个电钻，然后向我显示 Tailwind Traders 在出售的电钻以及我可在商店中的哪个位置找到它。

但是，让我们用其他图片来试一下。 我要返回主页，再次使用“按图购物”功能，但这次选择这张钳子的图片。 遗憾的是，应用分析图片后，将其识别为锤子。 这一结果明显不尽人意，因此我们现在来看看是否能找到问题原因，想办法使用计算机视觉纠正问题。 

### <a name="slide-how-computer-vision-works"></a>幻灯片：计算机视觉的工作原理

现在我们大致了解一下理论。 这不会涉及到很多的数学知识。

这些内容可帮助我们了解问题的原因及解决方法。

### <a name="slide-tasks-xkcd-comic"></a>幻灯片：任务（XKCD 漫画）

（暂停 10 秒）

计算机理解科幻小说中使用的照片。

5 年之后，这种识别能力并非有可能，而是非常容易实现。

### <a name="slide-how-neural-networks-work-brandon-rohrer"></a>幻灯片：神经网络的工作原理 (Brandon Rohrer)

在 Brandon Rohrer 的许可下改编。

请查看他的视频教程系列博客，其中深入介绍了 AI 和机器学习的各个方面。 

### <a name="slide-computer-vision--convolutional-neural-network"></a>幻灯片：计算机视觉/卷积神经网络

AI 基于“深度学习”，但“深度”并不意味着“深奥”。

这是一个简单的神经网络。 真实的神经网络包含的层要多得多。

它在设计上仅检测五个对象。 它无法识别其他任何内容。

### <a name="slide-trained-convolutional-nn"></a>幻灯片：经过训练的卷积神经网络

输入的图像位于左侧。 

每个节点处理并重新组合原始图像，将其缩小，直到最终出现单个值：分类置信度。

此处的输入是一辆自行车，右侧包含最高值的节点为“自行车”。 已正确识别该图像。

### <a name="slide-filters-1"></a>幻灯片：筛选器 (1)

由于时间有限，已跳过。

### <a name="slide-filters-2"></a>幻灯片：筛选器 (2)

由于时间有限，已跳过。

### <a name="slide-filters-3"></a>幻灯片：筛选器 (3)

由于时间有限，已跳过。

### <a name="slide-training-an-image-classifier"></a>幻灯片：训练图像分类器

但如何通过训练神经网络来做到这一点呢？

[点击声] 选择适当的筛选器。 每个筛选器按权重小网格（通常为 3x3 或 5x5）控制。

[点击声] 我们使用许多训练图像（其中的分类是已知的）选择了权重。 选择权重，以选择正确的分类（至少在大部分时间是正确的）

在现实视觉网络中，可能有数百万个权重需要选择。 我们如何确定权重？

### <a name="slide-learning-backpropagation"></a>幻灯片：学习：反向传播

此处涉及到大量的数学计算。

但除非你是 AI 工程师，否则可以忽略这一步。 只需使用权重已由其他人优化的网络。

这也许会涉及到 80% 的应用程序。 但是，如果你确实需要设计自己的神经网络和优化权重，可借助 Tensorflow 和 Pytorch 等工具。 AIML40 和 AIML50 中提供了操作方法。

### <a name="slide-pre-trained-convolutional-nn"></a>幻灯片：预训练的卷积神经网络

但是，只要你有权访问可以检测所需图像的神经网络，就只需提供图像，而网络会自动将图像分类。

有些模型不仅可以分类，还能检测对象的位置，或者以其他方式分析图像。

### <a name="slide-demo-cognitive-services-computer-vision"></a>幻灯片：演示：认知服务计算机视觉

认知服务计算机视觉提供可对数千个对象进行分类的强大神经网络。

可以在 aka.ms/try-computervision 上，使用简单的基于 Web 的 UI 来尝试该神经网络

现在让我们试一试。

### <a name="video-computer-vision-via-web"></a>视频：通过 Web 实现计算机视觉

[点击声] 这是认知服务计算机视觉页面。 如果在该页面上向下滚动一点，就会发现一个很不错的基于 Web 的窗体，该窗体可用于从 Web 或以本地文件形式上传图像进行分析。 接下来，让我们尝试上传这张戴着安全帽的男子的图片。 只需几秒钟，我们就能通过计算机视觉服务获得对该图片的分析结果。 左侧显示在该图像中检测到的对象，右侧显示包含详细分析的 JSON 输出。 其中包括在图像中检测到的对象的名称和位置，与图像关联的标记或标签的列表，对图像的纯语言描述（在本例中为“戴头盔的男人”）以及许多其他有用的信息。

### <a name="slide-cognitive-services-computer-vision"></a>幻灯片：认知服务计算机视觉

查找对象：已检测到两个对象。 “头戴用具”和“人”。

查看标记。 最高置信度：男人。 接下来是“头戴用具”。 “头盔”仅排在第 6 位。
尚未专门针对“安全帽”训练模型。

稍后我们将了解如何修复该问题。

若要将视觉整合到应用中，可以通过编程方式访问 API。 让我们了解一下。

### <a name="video-computer-vision-via-cli"></a>视频：通过 CLI 实现计算机视觉

可以使用任何可连接到 HTTP 终结点的语言来连接到认知服务 API，但我这里 [点击声] 是一个 bash 脚本，它使用 Azure CLI 创建资源，并使用“curl”连接到计算机视觉 API。 可以在本地 Shell 中安装 Azure CLI，但在这里，我使用 Visual Studio Code 中的“Azure 帐户”扩展来启动 Cloud Shell，这意味着无需安装任何程序。 等该 Shell 准备就绪后，就可以直接从此 bash 脚本执行命令。 

第一个命令创建一个资源组，我用它来保存对 API 进行身份验证所需的密钥。

下一步是创建密钥。 我正在创建一个综合认知服务密钥，它可以用于包括计算机视觉在内的许多服务。

然后，我们可以直接在终端显示该密钥。 [等待] 可以使用这两个密钥中的任何一个来与 API 对接，因此，我将这里的第一个密钥保存在环境变量中。

使用该密钥，我们可以连接到计算机视觉服务提供的终结点 URL，因此我们也将该 URL 保存在环境变量中。

然后可以选择要分析的图像。 在这里，我们提供一张图像的 URL，就是我们刚才看到的戴安全帽的男人图像。

现在，我们可以通过使用 curl 传入 JSON 输入，将密钥和图像 URL 传递到终结点中。 在短短几毫秒内，我们就获得了 JSON 形式的图像分析结果。 可以看到刚才在 Web 界面中看到的相同输出。

当然，我们可以使用任何喜欢的图像做到这一点。 让我们用其他图像再试一次，这次是一张电钻图片。 同样，我们可以使用 curl 将其传递给 API。 [等待] 有趣的是，与此图像关联的排名第一的标记是“相机”。很遗憾，它无法帮助我们搜索到真正的工具 - 我们要的是“电钻”。

### <a name="slide-adapting-computer-vision-models-with-your-own-data"></a>幻灯片：用你自己的数据改编计算机视觉模型

计算机视觉 API 不适用于“按图购物”。 

训练后检测的对象种类过多。

幸运的是，我们可以解决这个问题。 让我们暂时回到理论知识。

可通过某种方式来改编模型，使其既可以检测数千个对象，也可以仅检测所需的对象， 即使这些对象不是原始模型的一部分。 

让我们看看如何使用称作“迁移学习”的 AI 技术。 

### <a name="slide-transfer-learning"></a>幻灯片：迁移学习

与前面所述的卷积神经网络相同，只是剥除了最后一层。

倒数第二个层提供“特征”- 可将其视为数字矢量。 每张图像生成一组不同的特征。

我们不知道这些特征的含义，但它们往往可用于分类图像。

技巧：可以使用这些特征对一组新对象进行分类。

### <a name="slide-transfer-learning-training-1---with-the-hammer"></a>幻灯片：迁移学习训练（1 - 使用锤子图像）

使用迁移学习创建一个模型来识别锤子和安全帽。

传递锤子的图片，并收集特征。 此外传递“锤子”的二元指示符。 对大量的锤子重复上述操作。

### <a name="slide-transfer-learning-training-2---with-the-white-hard-hat"></a>幻灯片：迁移学习训练（2 - 使用安全帽图像）

现在，针对安全帽重复相同的操作。

在每种情况下，针对每个图像收集 8 个数据矢量和 1 个二元指示符。

总之，你会获得一个数据矢量的集合，且每个集合都有一个关联的二元结果。 

这样就可以创建一个简单的预测模型。

### <a name="slide-transfer-learning-trained-model"></a>幻灯片：迁移学习 - 已训练的模型

结果非常不错。

不需要大量的图像或计算能力。

这只是一个玩具示例，但原理也适用于大型模型。

### <a name="slide-microsoft-cognitive-services-custom-vision"></a>幻灯片：Microsoft 认知服务自定义视觉

你不必亲自训练迁移学习模型。

使用 Microsoft 预先训练的视觉模型之一，并通过自定义视觉使用自己的对象图像对该模型进行改编。

现在，让我们尝试使用它来构建一个“按图购物”的视觉模型。

### <a name="slide-demo-customized-object-recognition"></a>幻灯片：演示：自定义的对象识别

演示说明： https://github.com/microsoft/ignite-learning-paths-training-aiml/blob/master/aiml20/DEMO%20Custom%20Vision.md

### <a name="video-customvisionai"></a>视频：customvision.ai

[点击声] 现在，我已进入自定义视觉基于 Web 的界面。 它为我们提供了优秀的 UI，让我们可以在其中提供用于迁移学习分析的新图像。 可以在此项目中看到我已经上传了多张图片。 我上传了螺丝刀、钳子、电钻和锤子的图片，我将使用这些图片训练自定义模型。 我们还想检测 Tailwind Traders 销售的另一款产品：安全帽。 让我们单击“添加图像”，浏览到硬盘上收集了一些安全帽图片的文件夹，并全部选中这些图片，然后将其添加到服务中，同时提供“安全帽”标签用于训练。

上传这些文件需要花费一些时间，但在进行此操作时，请注意，此项目中的图像并不多：约 180 个，即五个类别中的每个类别各有数十个。 有时甚至更少。 尽管如此，由于我的五个对象类型截然不同，该模型的效果应该非常不错。

因此，让我们继续并单击“训练”按钮以开始迁移学习。 我们选择“快速训练”。 现在，它通过复杂的视觉模型运行所有这些图像，并使用迁移学习针对我们的五个类别创建预测模型。 只需几秒钟，我们的模型就做得有模有样了！
概率阈值设置了一个限制，低于该限制时我们完全无法预测任何分类。 如果我们仅接受置信度为 50% 或更高的分类，则其中 90.9% 的预测是正确的：这称为“精准率”。 整体而言，该模型正确地对 88.2% 的图像进行了分类：这称为“召回率”。 在你的应用中，请根据自己对做出错误召回以及完全不做出召回的容忍度选择阈值。 对于 Tailwind Traders，我们可将阈值设置得较低，因为向客户建议错误的产品并不是一件大事。 如果这是一个癌症检测应用，则你可能会做出其他选择。

现在，让我们使用模型之前未见过的新图像对模型进行试用。 我们通过单击“快速测试”按钮来实现此目的。 我们上传来自“test images”文件夹的新文件。 让我们用安全帽试试我们的模型。 你会看到，预测结果确实是“安全帽”，概率为 99.9%，因此，我们几乎可使用所选择的任何阈值完成此任务。

让我们试试其他图像：电钻。 我们的模型将图像识别为电钻的概率为 94.5%。 最后，让我们试试钳子的图片，其识别结果的置信度为 99.9%。

因此，即使我们只使用了不到 200 个图像对模型进行训练，我们的模型也能很好地完成任务。
那是因为我们将可能的标签约束为仅限于在 Tailwind Traders 销售的那些产品。

现在，我们对模型感到满意，可将其导出并合并到我们的应用中。 如果单击“导出”按钮，可将模型作为容器导出以用于 iOS 或 Android，或在我们的示例中，模型以通用 ONNX 格式导出。 现在，我们已将模型下载到硬盘上。

### <a name="slide-portable-deep-learning-models"></a>幻灯片：可移植深度学习模型

我们以 ONNX 格式导出了自定义模型。

ONNX 又称为“开放神经网络交换”，是 Microsoft 和 Facebook 联合推出的一种开放标准，旨在促进 AI 模型的自由交换和部署，并得到了众多应用程序和技术供应商的支持。

我们已使用 ONNX 运行时将导出的模型集成到网站中。

### <a name="slide-onnximagesearchtermpredictorcs"></a>幻灯片：ONNXImageSearchTermPredictor.cs

InferenceSession 引用导出的 .onnx 文件

模型将生成一个要传递到搜索中的分类标签。

### <a name="slide-demo-onnx"></a>幻灯片：演示：ONNX

演示：ONNX 部署

### <a name="video-kudu"></a>视频：Kudu

[点击声] 我们刚才从自定义视觉中导出的模型实际上是一个 ZIP 文件，其中包含实际的 ONNX 文件 model.onnx，这是我们刚才创建的神经网络的文本表示形式，也是一个清单文件。 

现有的 Tailwind Traders 网站已在使用计算机视觉模型，该模型以名为 products.onnx 的 ONNX 文件的形式表示。 问题在于，该模型无法正确识别我们在 Tailwind Traders 销售的许多产品。 我们将使用刚才从自定义视觉中导出的 model.onnx 文件，将其重命名为products.onnx，并在我们的 Web 应用中替换它，以便“按图购物”功能可识别我们对其进行训练的全部五种产品。

在 Azure 门户中，可以看到运行 Tailwind Traders 网站的应用服务资源。 现在可以在此应用服务中执行的操作就是转到“开发工具”部分，然后选择“高级工具”功能。 随后会启动 Kudu 界面。 界面启动后，可以使用调试控制台浏览网站文件系统。 让我们浏览到 products.onnx 文件所在的位置：site -> w-root -> Standalone -> OnnxModels。 现在，可将其替换为我们使用自定义视觉创建的 product.onnx 文件的新版本。

现在，返回应用服务，我们可以继续并重启 Web 服务器，这将使其在“按图购物”功能中使用新的 ONNX 模型。

### <a name="video-netron"></a>视频：Netron

[点击声] 在等待网站重启时，让我们深入了解刚才安装的 ONNX 模型。 Lutz Roeder 开发了一个不错的小型 Web 应用，名为 Netron，它使我们能够检查 ONNX 文件中的神经网络。 让我们继续，打开 product.onnx 文件。 现在可以看到模型代表的神经网络的实际层。 让我们放大一点，看看顶部的输入。 该输入是一个图像。 它是一个 3 层的 RGB 图像，大小为 224x224 像素。 实际上，在将用户提供的图像提供给 ONNX 运行时之前，我必须裁剪并缩小该图像。 计算机视觉系统的视觉效果很差是一个不太光彩的秘密 -- 它们在图像分辨率相当低的环境下工作 -- 但仍然有出色的表现。

现在，让我们缩小并滚动浏览网络。 可以看到由自定义视觉创建的神经网络中的所有层，每一层都可以转换输入图像、应用筛选器并重新组合输出图像，就像本讲座前面部分所述的那样。 但是，最终到达输出层时，会看到输出是一个包含五个值的列表 -- 即我们对其进行训练的五种产品：锤子、安全帽等 -- 以及标记为“损失”的这个值，这是模型针对每个类别预测的置信度。 在你的应用中，可选择自己的阈值用于设置所需的置信度。

不管怎样，Tailwind Traders 网站现在已重启，让我们回到主页，看看新视觉模型表现如何。 让我们继续并上传图片，然后再次使用测试图像之一进行尝试，特别是之前表现不佳的钳子图像。 可以看到，该网站确实没有将其视为锤子，而是搜索“钳子”，并向我展示了其提供的所有产品。

### <a name="slide-optimizing-app-ui-with-cognitive-services-personalizer"></a>幻灯片：使用认知服务个性化体验创建服务优化应用 UI

现在让我们演示另一个快速示例：个性化体验创建服务。

借助个性化体验创建服务，可通过从用户行为中学习，实时自定义应用的界面。

### <a name="slide-recommended-screenshot"></a>幻灯片：推荐（屏幕截图）

“推荐”部分显示一张较大的“主图”，以及几张小图。

个性化体验创建服务将选择各个部分的显示顺序

使用称作“强化学习”的 AI 技术。

### <a name="slide-personalizer-in-action"></a>幻灯片：个性化体验创建服务实践

多年来，Microsoft 一直致力于个性化体验创建服务的开发。 

XBox、必应和 MSN 新闻中都使用了该服务。

现在你也可以在自己的应用中使用个性化体验创建服务。

### <a name="slide-reinforcement-learning"></a>幻灯片：强化学习

个性化体验创建服务实现一种称作“强化学习”的 AI 技术。 工作原理如下。

[点击声] 假设我们要向用户显示一个主要操作。 [点击声] 用户可能不确定下一步该怎么做，[点击声] 但我们可以显示其中一项建议。 对于游戏应用，[点击声] 那可能是：“玩游戏”、“看视频”或“加入部落”。 [点击声] 根据该用户的历史记录和其他上下文信息（例如，他们的位置、当天时间和星期几），个性化体验创建服务将 [点击声] 排列可能的操作并 [点击声] 对要提升的最佳操作提出建议 [点击声]。 

希望用户会满意 [点击声]，但我们如何确定这一点呢？ 这取决于用户下一步要执行的操作，以及我们是否希望他们这样做。
根据我们的业务逻辑 [点击声]，我们将为接下来执行的操作分配一个“奖励评分”，评分范围为 0 至 1。 例如，花更多的时间玩游戏或阅读文章，或在商店里花更多的钱，可能会获得更高的奖励评分。 [点击声] 个性化体验创建服务将这些信息馈送回排名系统，以便下次我们需要安排某个活动时使用。

### <a name="slide-discovering-patterns-and-causality"></a>幻灯片：发现模式和因果关系

个性化体验创建服务不仅仅是一个推荐器系统。

探索模式可按指定的比率显示其他选项。

例如实时 A/B 测试。

### <a name="slide-personalizer-for-tailwind-traders"></a>幻灯片：适用于 Tailwind Traders 的个性化体验创建服务

上下文：时间、星期和浏览器 OS  

奖励评分：如果单击了特色类别，则为 1；否则为 0。

探索比率：20%

### <a name="slide-demo-personalizer"></a>幻灯片：演示：个性化体验创建服务

[点击声] 现在让我们在实践中了解个性化体验创建服务。 让我们返回到 Tailwind Traders 主页。 我之前没有提到的是，在这个“推荐”部分，产品部门的顺序是由个性化体验创建服务决定的。
在本例中，它将电气部门显示为主图。 我们刷新网站几次，也可以看到“探索”行为。
显然，个性化体验创建服务目前认为，在每天的这个时候，通过使用我在此处使用的浏览器和操作系统，Garden Center 获得了来自匿名用户的最佳参与度，但最终它会尝试不同的类别 - 此时将弹出管道，个性化体验创建服务将使用它来衡量参与度。

### <a name="slide-pre-built-ai-in-production"></a>幻灯片：生产环境中的预构建 AI

最后，请注意在将 AI 投入生产时的一些事项。

### <a name="slide-cost-considerations"></a>幻灯片：成本注意事项

首要考虑因素：成本。 

不熟悉 Azure？ 请使用此链接注册并获取 200 美元的免费额度。

[点击声] 开发规模的工作负荷一般是免费的 

[点击声] 费用在生产卷中产生

[点击声] 此链接按服务和区域列出了具体的详细信息

### <a name="slide-data-considerations"></a>幻灯片：数据注意事项

需考虑数据的去向及其用法。

数据将上传以用于推理，但用后会立即删除。 此链接提供了详细信息。

如果带宽是一个问题，或数据受到管控，请考虑使用容器。

### <a name="slide-deployment-with-containers"></a>幻灯片：使用容器的部署

可下载的容器中提供了一些服务。

请将容器安装在防火墙的后面，任何数据都不会发送到 Microsoft。

Internet 连接仅用于计费。 按正常费率计费。

### <a name="slide-ethical-considerations"></a>幻灯片：道德注意事项

最重要的幻灯片。

请了解 AI 应用对人类造成的道德影响。

使用合乎道德的框架：

使人们能够按他们的惯常方式实现更多的目的（而不是替代人类） 

包容所有类型的用户：确保每个人都能平等地通过你的应用程序受益 

公平且透明。

请记住，AI 的表现只能以训练它所用的数据质量为界限。 请确保你的应用程序适用于所有潜在用户。

如果尚未设置道德框架，可以从 Microsoft 自己的人工智能原则开始；可以通过此处的链接阅读详细信息。

### <a name="slide-wrapping-up"></a>幻灯片：总结

预构建的模型不能执行任何操作，但可以快速为你带来长足的发展。 

AI 由数据驱动。 请始终留意这些数据，以及可能出现的错误。

试试看！ 无需丰富的专业知识，但要考虑道德影响。

### <a name="slide-docs-alert"></a>幻灯片：文档提醒

有关 Azure 认知服务的所有详细信息，包括入门指南和参考，请查看 Microsoft Docs。

### <a name="slide-ms-learn-alert"></a>幻灯片：MS Learn 提醒

如果想要学习如何使用认知服务，可以在 Microsoft Learn 上找到免费的课程，这些课程将为你提供分步指导。

### <a name="slide-resources"></a>幻灯片：资源

Github 存储库中的所有链接和代码。

如果你想获得人工智能或数据科学方面的 Microsoft 认证，今天我们面向与会者提供免费认证特殊优惠：有关详细信息，请查看该链接。

我随时乐意解答各种问题。 （还有 ...）

谢谢。
