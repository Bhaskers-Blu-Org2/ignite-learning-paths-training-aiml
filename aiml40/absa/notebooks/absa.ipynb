{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azureml\n",
    "from shutil import copyfile, rmtree\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Workspace, Datastore, Experiment, Environment, Model\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "import spacy\n",
    "from nlp_architect.models.absa.inference.inference import SentimentInference\n",
    "from spacy import displacy\n",
    "from nlp_architect.models.absa.inference.data_types import TermType\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name     = \"absa-cluster\"\n",
    "experiment_name  = \"absa\"\n",
    "model_name       = \"absa\"\n",
    "aci_deploy_name  = \"absa-aci\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "#   \n",
    "# Step 1 - Setup your environment\n",
    "#   \n",
    "![title](images/step1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(\"Using workspace:\",ws.name,\"in region\", ws.location)\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach a Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for your CPU cluster\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Using compute cluster:', cluster_name)\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3_V2',\n",
    "                                                           vm_priority='lowpriority',\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the default datastore\n",
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "# Step 2 - Experiment with your data & models\n",
    "#   \n",
    "![title](images/step2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment or connect if it exists\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--data_folder': ds,\n",
    "    '--large': 'yes'\n",
    "}\n",
    "\n",
    "nlp_est = Estimator(source_directory='../scripts',\n",
    "                   script_params=script_params,\n",
    "                   compute_target=cluster,\n",
    "                   environment_variables = {'NLP_ARCHITECT_BE':'CPU'},\n",
    "                   entry_script='train.py',\n",
    "                   pip_packages=['git+https://github.com/NervanaSystems/nlp-architect.git@absa',\n",
    "                                 'spacy==2.1.8']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit and run the estimator\n",
    "run = exp.submit(nlp_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a previous run and show the details\n",
    "run = [r for r in exp.get_runs() if r.id == 'absa_1580996552_8fcdf147'][0]\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name = model_name, \n",
    "                     model_path = 'outputs', \n",
    "                     model_framework =  Model.Framework.TENSORFLOW,\n",
    "                     model_framework_version = '1.13',\n",
    "                     description = 'Aspect Based Sentiment Analysis - Intel',\n",
    "                     tags={'area': 'NLP', 'type': 'unsupervised', 'model_author': \"INTEL\"},\n",
    "                     resource_configuration = ResourceConfiguration(cpu=1, memory_in_gb=2))\n",
    "\n",
    "print('version:',model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our model On Sample Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model \n",
    "# model = Model(ws, 'absa')\n",
    "Path(\"../temp\").mkdir(parents=True, exist_ok=True)\n",
    "model.download(exist_ok=True,target_dir=\"../temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# When you run for the first time, you will need to run twice (Spacy install)\n",
    "c_aspect_lex = '../temp/outputs/generated_aspect_lex.csv'\n",
    "c_opinion_lex = '../temp/outputs/generated_opinion_lex_reranked.csv' \n",
    "inference = SentimentInference(c_aspect_lex, c_opinion_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the predictions\n",
    "docs = [\"Loved the sweater but hated the pants\",\n",
    "       \"Really great outfit, I really like the shirt\",\n",
    "       \"The shoes are bad, but perfect blouse\"]\n",
    "\n",
    "sentiment_docs = []\n",
    "\n",
    "for doc_raw in docs:\n",
    "    sentiment_doc = inference.run(doc=doc_raw)\n",
    "    sentiment_docs.append(sentiment_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions on the data\n",
    "ents = []\n",
    "for doc in sentiment_docs:    \n",
    "    doc_viz = {'text':doc._doc_text, 'ents':[]}\n",
    "    for s in doc._sentences:\n",
    "        for ev in s._events:\n",
    "            for e in ev:\n",
    "                if e._type == TermType.ASPECT:\n",
    "                    ent = {'start': e._start, 'end': e._start + e._len,'label':str(e._polarity.value), 'text':str(e._text)}\n",
    "                    if all(kown_e['start'] != ent['start'] for kown_e in ents):\n",
    "                        ents.append(ent)\n",
    "                        doc_viz['ents'].append(ent)\n",
    "    doc_viz['ents'].sort(key=lambda m: m[\"start\"])\n",
    "    displacy.render(doc_viz, style=\"ent\", options={'colors':{'POS':'#7CFC00', 'NEG':'#FF0000'}}, manual=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "#   \n",
    "# Step 3 -  Deploy your model in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest registered model\n",
    "model = Model(ws, name=model_name)\n",
    "print(\"Loaded model version:\",model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = [\"azureml-defaults\", \n",
    "       \"azureml-monitoring\", \n",
    "       \"git+https://github.com/NervanaSystems/nlp-architect.git@absa\", \n",
    "       \"spacy==2.1.8\"]\n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=pip)\n",
    "\n",
    "Path(\"../temp\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(\"../temp/myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "deploy_env = Environment.from_conda_specification('absa_env', \"../temp/myenv.yml\")\n",
    "deploy_env.environment_variables={'NLP_ARCHITECT_BE': 'CPU'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(environment=deploy_env, entry_script=\"../scripts/score.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deployment config\n",
    "deploy_config = AciWebservice.deploy_configuration(\n",
    "                    cpu_cores = model.resource_configuration.cpu, \n",
    "                    memory_gb = model.resource_configuration.memory_in_gb,\n",
    "                    description='Aspect-Based Sentiment Analysis - Intel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to an ACI\n",
    "deployment = Model.deploy(ws, \n",
    "                name=aci_deploy_name, \n",
    "                models = [model], \n",
    "                inference_config = inference_config, \n",
    "                deployment_config = deploy_config, \n",
    "                overwrite = True)\n",
    "\n",
    "deployment.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the scoring details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to previous deployment\n",
    "deployment = AciWebservice(ws, aci_deploy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scoring endpoint:\",deployment.scoring_uri)\n",
    "print(\"Test uri:\",\"http://aiml40.azurewebsites.net/?url=\"+deployment.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}